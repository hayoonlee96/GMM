{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel as C\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import font_manager, rc\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import scipy as sp\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "csfont = {'fontname':'Times New Roman'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/AlexanderFabisch/gmr\n",
    "\n",
    "https://towardsdatascience.com/gaussian-mixture-modelling-gmm-833c88587c7f\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html\n",
    "\n",
    "http://norman3.github.io/prml/docs/chapter09/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 112) (101, 112) (101, 112) (101, 112) (101, 112) (101, 112)\n",
      "(101, 112) (101, 112) (101, 112) (101, 112) (101, 112) (101, 112)\n",
      "(101, 112) (101, 112) (101, 112) (101, 112) (101, 112) (101, 112)\n",
      "(101, 111) (101, 111) (101, 111) (101, 111) (101, 111) (101, 111)\n",
      "(101, 223) (101, 223) (101, 223) (101, 223) (101, 223) (101, 223)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'D:\\Dropbox\\0. HY\\5. KBU_gait\\00. Full data')\n",
    "#os.chdir(r'C:\\Users\\gkdbs\\Dropbox\\0. HY\\5. KBU_gait\\00. Full data')\n",
    "\n",
    "dataset = pd.read_csv('normal_left_perc_x.csv', sep=',',header=None) #.dropna(axis=0)\n",
    "nor_left_x_grf = np.transpose(dataset) \n",
    "dataset = pd.read_csv('normal_left_perc_y.csv', sep=',',header=None)\n",
    "nor_left_y_grf = np.transpose(dataset)\n",
    "dataset = pd.read_csv('normal_left_perc_z.csv', sep=',',header=None)\n",
    "nor_left_z_grf = np.transpose(dataset)\n",
    "\n",
    "dataset = pd.read_csv('mo_normal_left_perc_x.csv', sep=',',header=None) #.dropna(axis=0)\n",
    "nor_left_x_mo = np.transpose(dataset)\n",
    "nor_left_x_mo = nor_left_x_mo.drop(columns=[99])\n",
    "nor_left_x_mo.columns = np.arange(nor_left_x_mo.shape[1])\n",
    "dataset = pd.read_csv('mo_normal_left_perc_y.csv', sep=',',header=None)\n",
    "nor_left_y_mo = np.transpose(dataset)\n",
    "nor_left_y_mo = nor_left_y_mo.drop(columns=[99])\n",
    "nor_left_y_mo.columns = np.arange(nor_left_y_mo.shape[1])\n",
    "dataset = pd.read_csv('mo_normal_left_perc_z.csv', sep=',',header=None)\n",
    "nor_left_z_mo = np.transpose(dataset)\n",
    "nor_left_z_mo = nor_left_z_mo.drop(columns=[99])\n",
    "nor_left_z_mo.columns = np.arange(nor_left_z_mo.shape[1])\n",
    "\n",
    "dataset = pd.read_csv('normal_right_perc_x.csv', sep=',',header=None) #.dropna(axis=0)\n",
    "nor_right_x_grf = np.transpose(dataset) #-np.mean(np.transpose(dataset))\n",
    "dataset = pd.read_csv('normal_right_perc_y.csv', sep=',',header=None)\n",
    "nor_right_y_grf = np.transpose(dataset)\n",
    "dataset = pd.read_csv('normal_right_perc_z.csv', sep=',',header=None)\n",
    "nor_right_z_grf = np.transpose(dataset)\n",
    "\n",
    "dataset = pd.read_csv('mo_normal_right_perc_x.csv', sep=',',header=None) #.dropna(axis=0)\n",
    "nor_right_x_mo = np.transpose(dataset)\n",
    "nor_right_x_mo = nor_right_x_mo.drop(columns=[99])\n",
    "nor_right_x_mo.columns = np.arange(nor_right_x_mo.shape[1])\n",
    "dataset = pd.read_csv('mo_normal_right_perc_y.csv', sep=',',header=None)\n",
    "nor_right_y_mo = np.transpose(dataset)\n",
    "nor_right_y_mo = nor_right_y_mo.drop(columns=[99])\n",
    "nor_right_y_mo.columns = np.arange(nor_right_y_mo.shape[1])\n",
    "dataset = pd.read_csv('mo_normal_right_perc_z.csv', sep=',',header=None)\n",
    "nor_right_z_mo = np.transpose(dataset)\n",
    "nor_right_z_mo = nor_right_z_mo.drop(columns=[99])\n",
    "nor_right_z_mo.columns = np.arange(nor_right_z_mo.shape[1])\n",
    "\n",
    "print(nor_left_x_grf.shape, nor_left_y_grf.shape, nor_left_z_grf.shape,\n",
    "      nor_left_x_mo.shape, nor_left_y_mo.shape, nor_left_z_mo.shape)\n",
    "print(nor_right_x_grf.shape, nor_right_y_grf.shape, nor_right_z_grf.shape, \n",
    "      nor_right_x_mo.shape, nor_right_y_mo.shape, nor_right_z_mo.shape)\n",
    "\n",
    "nor_right_x_grf = -nor_right_x_grf\n",
    "#nor_right_x_cop = -nor_right_x_cop\n",
    "nor_right_y_mo = -nor_right_y_mo\n",
    "nor_right_z_mo = -nor_right_z_mo\n",
    "\n",
    "#################################################################################\n",
    "nor_right_x_grf = nor_right_x_grf.drop(columns=[35])\n",
    "nor_right_x_grf.columns = np.arange(nor_right_x_grf.shape[1])\n",
    "nor_right_y_grf = nor_right_y_grf.drop(columns=[35])\n",
    "nor_right_y_grf.columns = np.arange(nor_right_y_grf.shape[1])\n",
    "nor_right_z_grf = nor_right_z_grf.drop(columns=[35])\n",
    "nor_right_z_grf.columns = np.arange(nor_right_z_grf.shape[1])\n",
    "\n",
    "nor_right_x_mo = nor_right_x_mo.drop(columns=[35])\n",
    "nor_right_x_mo.columns = np.arange(nor_right_x_mo.shape[1])\n",
    "nor_right_y_mo = nor_right_y_mo.drop(columns=[35])\n",
    "nor_right_y_mo.columns = np.arange(nor_right_y_mo.shape[1])\n",
    "nor_right_z_mo = nor_right_z_mo.drop(columns=[35])\n",
    "nor_right_z_mo.columns = np.arange(nor_right_z_mo.shape[1])\n",
    "\n",
    "print(nor_left_x_grf.shape, nor_left_y_grf.shape, nor_left_z_grf.shape,\n",
    "      nor_left_x_mo.shape, nor_left_y_mo.shape, nor_left_z_mo.shape)\n",
    "print(nor_right_x_grf.shape, nor_right_y_grf.shape, nor_right_z_grf.shape, \n",
    "      nor_right_x_mo.shape, nor_right_y_mo.shape, nor_right_z_mo.shape)\n",
    "\n",
    "#################################################################################\n",
    "nor_mix_x_grf = np.transpose(np.transpose(nor_left_x_grf).append(np.transpose(nor_right_x_grf)))\n",
    "nor_mix_y_grf = np.transpose(np.transpose(nor_left_y_grf).append(np.transpose(nor_right_y_grf)))\n",
    "nor_mix_z_grf = np.transpose(np.transpose(nor_left_z_grf).append(np.transpose(nor_right_z_grf)))\n",
    "\n",
    "nor_mix_x_mo = np.transpose(np.transpose(nor_left_x_mo).append(np.transpose(nor_right_x_mo)))\n",
    "nor_mix_y_mo = np.transpose(np.transpose(nor_left_y_mo).append(np.transpose(nor_right_y_mo)))\n",
    "nor_mix_z_mo = np.transpose(np.transpose(nor_left_z_mo).append(np.transpose(nor_right_z_mo)))\n",
    "\n",
    "nor_mix_x_grf.columns = np.arange(nor_mix_x_grf.shape[1])\n",
    "nor_mix_y_grf.columns = np.arange(nor_mix_y_grf.shape[1])\n",
    "nor_mix_z_grf.columns = np.arange(nor_mix_z_grf.shape[1])\n",
    "nor_mix_x_mo.columns = np.arange(nor_mix_x_mo.shape[1])\n",
    "nor_mix_y_mo.columns = np.arange(nor_mix_y_mo.shape[1])\n",
    "nor_mix_z_mo.columns = np.arange(nor_mix_z_mo.shape[1])\n",
    "\n",
    "print(nor_mix_x_grf.shape, nor_mix_y_grf.shape, nor_mix_z_grf.shape, \n",
    "      nor_mix_x_mo.shape, nor_mix_y_mo.shape, nor_mix_z_mo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM + GMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    ax = ax or plt.gca()    \n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance) # SVD 사용 for PCA\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height, angle, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mvn_test(object):\n",
    "    def __init__(self, mean=None, covariance=None):\n",
    "        self.mean = mean\n",
    "        self.covariance = covariance\n",
    "        self.norm = None\n",
    "    def make_mvn(self, X, bessels_correction=True):\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        bias = 0 if bessels_correction else 1\n",
    "        self.covariance = np.cov(X, rowvar=0, bias=bias)\n",
    "        self.norm = None\n",
    "        return self\n",
    "    \n",
    "    def to_probability_density(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        C = self.covariance\n",
    "        try:\n",
    "            L = sp.linalg.cholesky(C, lower=True)\n",
    "        except np.linalg.LinAlgError:\n",
    "            C = self.covariance + 1e-6 * np.eye(n_features)\n",
    "            L = sp.linalg.cholesky(C, lower=True)\n",
    "        D = X - self.mean\n",
    "        cov_sol = sp.linalg.solve_triangular(L, D.T, lower=True).T\n",
    "        if self.norm is None:\n",
    "            self.norm = 0.5 / np.pi ** (0.5 * n_features) / sp.linalg.det(L)\n",
    "\n",
    "        DpD = np.sum(cov_sol ** 2, axis=1)\n",
    "        return self.norm * np.exp(-0.5 * DpD)\n",
    "    \n",
    "    def marginalize(self, indices):\n",
    "        return mvn_test(mean=self.mean[indices], covariance=self.covariance[np.ix_(indices, indices)])\n",
    "    def _condition(self, i1, i2, X):\n",
    "        cov_12 = self.covariance[np.ix_(i1, i2)]\n",
    "        cov_11 = self.covariance[np.ix_(i1, i1)]\n",
    "        cov_22 = self.covariance[np.ix_(i2, i2)]\n",
    "        a = np.asarray_chkfinite(cov_22)\n",
    "        s, u = linalg.eigh(a, lower=True)\n",
    "        cond = None\n",
    "        if cond in [None, -1]:\n",
    "            t = u.dtype.char.lower()\n",
    "            factor = {'f': 1E3, 'd': 1E6}\n",
    "            cond = factor[t] * np.finfo(t).eps\n",
    "        above_cutoff = (abs(s) > cond * np.max(abs(s)))\n",
    "        psigma_diag = np.zeros_like(s)\n",
    "        psigma_diag[above_cutoff] = 1.0 / s[above_cutoff]\n",
    "        prec_22 = np.dot(u * psigma_diag, np.conjugate(u).T)\n",
    "        regression_coeffs = cov_12.dot(prec_22)\n",
    "        mean = self.mean[i1] + regression_coeffs.dot((X - self.mean[i2]).T).T\n",
    "        covariance = cov_11 - regression_coeffs.dot(cov_12.T)\n",
    "        return mean, covariance\n",
    "    \n",
    "    def condition(self, indices, x):\n",
    "        inv = np.ones(self.mean.shape[0], dtype=np.bool)\n",
    "        inv[indices] = False\n",
    "        inv, = np.where(inv)\n",
    "        mean, covariance = self._condition(inv, indices, x)\n",
    "        return mvn_test(mean=mean, covariance=covariance)\n",
    "    \n",
    "    def condition_multiple(self, indices, X):\n",
    "        inv = np.ones(self.mean.shape[0], dtype=np.bool)\n",
    "        inv[indices] = False\n",
    "        inv, = np.where(inv)\n",
    "        return self._condition(inv, indices, X)\n",
    "    \n",
    "    def to_ellipse(self, factor=1.0):\n",
    "        vals, vecs = sp.linalg.eigh(self.covariance)\n",
    "        order = vals.argsort()[::-1]\n",
    "        vals, vecs = vals[order], vecs[:, order]\n",
    "        angle = np.arctan2(*vecs[:, 0][::-1])\n",
    "        width, height = factor * np.sqrt(vals)\n",
    "        return angle, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, n_clusters, n_iters):\n",
    "        self.n_clusters = n_clusters \n",
    "        self.n_iters= n_iters\n",
    "        \n",
    "    def get_params(self):\n",
    "        return (self.mean, self.pi, self.sigma)\n",
    "    \n",
    "    def initialize(self, X):\n",
    "        n_clusters = self.n_clusters\n",
    "        kmeans = KMeans(n_clusters= n_clusters, init=\"k-means++\", max_iter=500, algorithm = 'auto')\n",
    "        fitted = kmeans.fit(X)\n",
    "        prediction = kmeans.predict(X)\n",
    "        \n",
    "        d = X.shape[1]\n",
    "        labels = np.unique(prediction) \n",
    "        self.initial_means = np.zeros((self.n_clusters, d))\n",
    "        self.initial_cov = np.zeros((self.n_clusters, d, d))\n",
    "        self.initial_pi = np.zeros(self.n_clusters)\n",
    "        \n",
    "        counter=0\n",
    "        for label in labels:\n",
    "            ids = np.where(prediction == label) # returns indices\n",
    "            self.initial_pi[counter] = len(ids[0]) / X.shape[0]\n",
    "            self.initial_means[counter,:] = np.mean(X[ids], axis = 0)\n",
    "            de_meaned = X[ids] - self.initial_means[counter,:]\n",
    "            Nk = X[ids].shape[0] # number of data points in current gaussian\n",
    "            self.initial_cov[counter,:, :] = np.dot(self.initial_pi[counter] * de_meaned.T, de_meaned) / Nk            \n",
    "            counter+=1\n",
    "        assert np.sum(self.initial_pi) == 1    \n",
    "        return (self.initial_means, self.initial_cov, self.initial_pi)\n",
    "    \n",
    "    def _e_step(self, X, pi, mean, sigma):\n",
    "        N = X.shape[0] \n",
    "        self.gamma = np.zeros((N, self.n_clusters))\n",
    "        const_c = np.zeros(self.n_clusters)        \n",
    "        self.mean = self.mean if self.initial_means is None else self.initial_means\n",
    "        self.pi = self.pi if self.initial_pi is None else self.initial_pi\n",
    "        self.sigma = self.sigma if self.initial_cov is None else self.initial_cov\n",
    "\n",
    "        for c in range(self.n_clusters):\n",
    "            # Posterior Distribution using Bayes Rule\n",
    "            self.gamma[:,c] = self.pi[c] * mvn.pdf(X, self.mean[c,:], self.sigma[c])\n",
    "        # normalize across columns to make a valid probability\n",
    "        gamma_norm = np.sum(self.gamma, axis=1)[:,np.newaxis]\n",
    "        self.gamma /= gamma_norm\n",
    "        return self.gamma\n",
    "    \n",
    "    def _m_step(self, X, gamma):\n",
    "        N = X.shape[0] # number of objects\n",
    "        n_clusters = self.gamma.shape[1] # number of n_clusterss\n",
    "        d = X.shape[1] # dimension of each object\n",
    "\n",
    "        self.pi = np.mean(self.gamma, axis = 0)\n",
    "        self.mean = np.dot(self.gamma.T, X) / np.sum(self.gamma, axis = 0)[:,np.newaxis]\n",
    "\n",
    "        for c in range(n_clusters):\n",
    "            x = X - self.mean[c, :] # (N x d)\n",
    "            gamma_diag = np.diag(self.gamma[:,c]) # 1D array를 대각행렬로 만듬\n",
    "            x_mean = np.matrix(x)\n",
    "            gamma_diag = np.matrix(gamma_diag)\n",
    "            sigma_c = x.T * gamma_diag * x\n",
    "            self.sigma[c,:,:]=(sigma_c) / np.sum(self.gamma, axis = 0)[:,np.newaxis][c]\n",
    "        return self.pi, self.mean, self.sigma\n",
    "    \n",
    "    \n",
    "    def _compute_loss_function(self, X, pi, mean, sigma):\n",
    "        # pi: (n_clusters), mean: (n_clusters x d), sigma: (n_clusters x d x d)\n",
    "\n",
    "        N = X.shape[0]\n",
    "        n_clusters = self.gamma.shape[1]\n",
    "        self.loss = np.zeros((N, n_clusters))\n",
    "\n",
    "        for c in range(n_clusters):\n",
    "            dist = mvn(self.mean[c], self.sigma[c],allow_singular=True)\n",
    "            self.loss[:,c] = self.gamma[:,c] * (np.log(self.pi[c]+0.00001)+dist.logpdf(X)-np.log(self.gamma[:,c]+0.000001))\n",
    "        self.loss = np.sum(self.loss)\n",
    "        return self.loss\n",
    "    \n",
    "    def fit(self, X):\n",
    "        d = X.shape[1]\n",
    "        self.mean, self.sigma, self.pi =  self.initialize(X)\n",
    "        try:\n",
    "            for run in range(self.n_iters):  \n",
    "                self.gamma  = self._e_step(X, self.mean, self.pi, self.sigma)\n",
    "                self.pi, self.mean, self.sigma = self._m_step(X, self.gamma)\n",
    "                loss = self._compute_loss_function(X, self.pi, self.mean, self.sigma)\n",
    "                if run % 10 == 0:\n",
    "                    print(\"Iteration: %d Loss: %0.6f\" %(run, loss))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return self\n",
    "    \n",
    "    def predict_labels(self, X):\n",
    "        # labels: predicted n_clusters based on highest probability gamma\n",
    "        labels = np.zeros((X.shape[0], self.n_clusters))\n",
    "        for c in range(self.n_clusters):\n",
    "            labels [:,c] = self.pi[c] * mvn.pdf(X, self.mean[c,:], self.sigma[c])\n",
    "        post_proba = labels\n",
    "        final_labels  = labels.argmax(1)\n",
    "        return post_proba, final_labels \n",
    "\n",
    "    def cond_predict(self, indices, X):\n",
    "        n_samples, n_features_1 = X.shape\n",
    "        n_features_2 = self.mean.shape[1] - n_features_1\n",
    "        Y = np.empty((n_samples, n_features_2))\n",
    "        for n in range(n_samples):            \n",
    "            x = X[n]\n",
    "            n_features = self.mean.shape[1] - len(indices)\n",
    "            priors = np.empty(self.n_clusters)\n",
    "            means = np.empty((self.n_clusters, n_features))\n",
    "            covariances = np.empty((self.n_clusters, n_features, n_features))\n",
    "            for k in range(self.n_clusters):\n",
    "                mvn = mvn_test(mean=self.mean[k], covariance=self.sigma[k])\n",
    "                conditioned = mvn.condition(indices, x)\n",
    "                priors[k] = (self.pi[k] * mvn.marginalize(indices).to_probability_density(x))\n",
    "                means[k] = conditioned.mean\n",
    "                covariances[k] = conditioned.covariance\n",
    "            priors /= priors.sum()            \n",
    "            Y[n] = priors.dot(means)\n",
    "        return Y\n",
    "   \n",
    "    def to_ellipses(self, factor=1.0):\n",
    "        res = []\n",
    "        for k in range(self.n_clusters):\n",
    "            mvn = mvn_test(mean=self.mean[k], covariance=self.sigma[k])\n",
    "            res.append((self.mean[k], mvn.to_ellipse(factor)))\n",
    "        return res\n",
    "    \n",
    "def plot_error_ellipses(ax, gmm, colors=None):\n",
    "    from matplotlib.patches import Ellipse\n",
    "    from itertools import cycle\n",
    "    if colors is not None:\n",
    "        colors = cycle(colors)\n",
    "    for factor in np.linspace(0.5, 4.0, 8):\n",
    "        for mean, (angle, width, height) in gmm.to_ellipses(factor):\n",
    "            ell = Ellipse(xy=mean, width=width, height=height,\n",
    "                          angle=np.degrees(angle))\n",
    "            ell.set_alpha(0.25)\n",
    "            if colors is not None:\n",
    "                ell.set_color(next(colors))\n",
    "            ax.add_artist(ell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features of GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Loss: 1461.537664\n",
      "Iteration: 10 Loss: 1466.710421\n",
      "Iteration: 20 Loss: 1466.710423\n",
      "Iteration: 30 Loss: 1466.710423\n",
      "Iteration: 40 Loss: 1466.710423\n",
      "Iteration: 50 Loss: 1466.710423\n",
      "0\n",
      "[[0.98424688 0.80349769 0.02562777 0.75649805 0.0335109  0.29987092]\n",
      " [0.47603546 0.13534754 0.37238575 0.21811814 0.39502876 0.80173843]\n",
      " [0.24223283 0.83524646 0.69877372 0.92728619 0.79521136 0.33923757]\n",
      " [0.87372767 0.77294773 0.07063909 0.4282268  0.05037538 0.27463471]\n",
      " [0.49997051 1.         0.39789149 0.98714463 0.5192008  0.27923283]\n",
      " [0.90928635 0.42503545 0.06260498 0.2203718  0.12968208 0.7357989 ]\n",
      " [0.69551569 0.31229285 0.22125309 0.0605631  0.02536942 0.89476257]]\n"
     ]
    }
   ],
   "source": [
    "data_dimension = 6\n",
    "number_of_gaussian = 7\n",
    "iteration = 60\n",
    "###########################################################\n",
    "\n",
    "for nn in np.arange(1): #np.arange(nor_mix_x_grf.shape[1]):\n",
    "\n",
    "    ## Load individual data\n",
    "    temp = pd.DataFrame(np.zeros((101,6)))\n",
    "    temp[0] = pd.DataFrame(nor_mix_x_grf.iloc[:,nn])\n",
    "    temp[1] = pd.DataFrame(nor_mix_y_grf.iloc[:,nn])\n",
    "    temp[2] = pd.DataFrame(nor_mix_z_grf.iloc[:,nn])\n",
    "    temp[3] = pd.DataFrame(nor_mix_x_mo.iloc[:,nn])\n",
    "    temp[4] = pd.DataFrame(nor_mix_y_mo.iloc[:,nn])\n",
    "    temp[5] = pd.DataFrame(nor_mix_z_mo.iloc[:,nn])\n",
    "\n",
    "    fit_data = np.array(temp)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(fit_data)\n",
    "    scaled_fit_data = scaler.transform(fit_data)\n",
    "    fit_data = scaled_fit_data\n",
    "\n",
    "    ## GMM\n",
    "    model = GMM(number_of_gaussian, iteration)\n",
    "    fitted_values = model.fit(np.array(fit_data))\n",
    "    \n",
    "    centers_g1 = np.zeros((number_of_gaussian,data_dimension))\n",
    "    centers_g2 = np.zeros((number_of_gaussian,data_dimension))\n",
    "    centers_g3 = np.zeros((number_of_gaussian,data_dimension))\n",
    "    centers_g4 = np.zeros((number_of_gaussian,data_dimension))\n",
    "    centers_g5 = np.zeros((number_of_gaussian,data_dimension))\n",
    "    centers_g6 = np.zeros((number_of_gaussian,data_dimension))\n",
    "    centers_g7 = np.zeros((number_of_gaussian,data_dimension))\n",
    "    \n",
    "    for i in range(model.n_clusters):\n",
    "        density = mvn(cov=model.sigma[i], mean=model.mean[i]).logpdf(fit_data)\n",
    "        centers[i, :] = fit_data[np.argmax(density)]\n",
    "\n",
    "    print(nn)\n",
    "\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
